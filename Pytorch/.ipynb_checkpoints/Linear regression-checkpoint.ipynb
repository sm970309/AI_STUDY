{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Singlevariable Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x_train = torch.FloatTensor([[1],[2],[3]])\n",
    "y_train = torch.FloatTensor([[2],[4],[6]])\n",
    "\n",
    "W = torch.zeros(1)\n",
    "b = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.optim 없이 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18.6667) tensor([0.]) tensor([0.])\n",
      "tensor(0.0378) tensor([1.7740]) tensor([0.5137])\n",
      "tensor(0.0184) tensor([1.8425]) tensor([0.3579])\n",
      "tensor(0.0089) tensor([1.8903]) tensor([0.2494])\n",
      "tensor(0.0043) tensor([1.9236]) tensor([0.1738])\n",
      "tensor(0.0021) tensor([1.9467]) tensor([0.1211])\n",
      "tensor(0.0010) tensor([1.9629]) tensor([0.0844])\n",
      "tensor(0.0005) tensor([1.9741]) tensor([0.0588])\n",
      "tensor(0.0002) tensor([1.9820]) tensor([0.0410])\n",
      "tensor(0.0001) tensor([1.9874]) tensor([0.0285])\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "lr = 0.01\n",
    "for epoch in range(epochs):\n",
    "    hypothesis = x_train*W+b\n",
    "    cost = torch.mean((hypothesis-y_train)**2)\n",
    "    \n",
    "    gradient_W = torch.sum((hypothesis-y_train)*x_train)\n",
    "    gradient_b = torch.sum(hypothesis-y_train)\n",
    "    \n",
    "    if epoch%100==0:\n",
    "        print(cost,W,b)\n",
    "    W -= lr*gradient_W\n",
    "    b -= lr*gradient_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.9912]), tensor([0.0199]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.optim 사용하여 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1],[2],[3]])\n",
    "y_train = torch.FloatTensor([[2],[4],[6]])\n",
    "\n",
    "W = torch.zeros(1,requires_grad=True)\n",
    "b = torch.zeros(1,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([W,b],lr=0.01)\n",
    "epochs = 10000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    hypothesis = x_train*W+b\n",
    "    cost = torch.mean((hypothesis-y_train)**2)\n",
    "    \n",
    "    optimizer.zero_grad() # gradient 초기화\n",
    "    cost.backward() #gradient 계산\n",
    "    optimizer.step() #optimizer 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W :1.9999957084655762, b :8.701807018951513e-06\n"
     ]
    }
   ],
   "source": [
    "print(f'W :{W[0]}, b :{b[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Multivariable Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * n x 3 matrix\n",
    "> * 그에 따른 가중치 W도 3x1 로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73,80,75],\n",
    "                            [93,88,93],\n",
    "                            [89,91,90],\n",
    "                            [96,98,100],\n",
    "                            [73,66,70]])\n",
    "y_train = torch.FloatTensor([[152],[185],[180],[196],[142]])\n",
    "\n",
    "W = torch.zeros((3,1),requires_grad=True)\n",
    "b = torch.zeros(1,requires_grad=True)\n",
    "\n",
    "optimizer = torch.optim.SGD([W,b],lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    hypothesis = x_train@W+b\n",
    "    cost = torch.mean((hypothesis-y_train)**2)\n",
    "    \n",
    "    optimizer.zero_grad() # gradient 초기화\n",
    "    cost.backward() #gradient 계산\n",
    "    optimizer.step() #optimizer 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.8881, 0.4642, 0.6582], grad_fn=<SqueezeBackward0>),\n",
       " tensor([0.0195], requires_grad=True),\n",
       " tensor(0.2712, grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.squeeze(),b,cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.module을 이용해 구현\n",
    "> * 기존 hypothesis와 loss를 미리 구현\n",
    "> * 모델이 바뀔때마다 쉽게 수정 가능\n",
    "> * 버그도 적음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MultivariabelLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3,1) # linear는 3x1 을 가지는 weight\n",
    "    def forward(self,x):\n",
    "        return self.linear(x) # forward를 linear로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultivariabelLinearRegressionModel()\n",
    "optimizer = torch.optim.SGD([W,b],lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    prediction = model(x_train) # forward 계산\n",
    "    cost = nn.functional.mse_loss(prediction,y_train) # mse_loss 계산\n",
    "    \n",
    "    optimizer.zero_grad() # gradient 초기화\n",
    "    cost.backward() #gradient 계산\n",
    "    optimizer.step() #optimizer 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8881],\n",
       "         [0.4642],\n",
       "         [0.6582]], requires_grad=True),\n",
       " tensor([0.0195], requires_grad=True))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dataset 사용\n",
    "> * Dataset을 사용하여 minibatch 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_data = [[73,80,75],\n",
    "                        [93,88,93],\n",
    "                        [89,91,90],\n",
    "                        [96,98,100],\n",
    "                        [73,66,70]]\n",
    "        self.y_data = [[152],[185],[180],[196],[142]]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    def __getitem__(self,idx):\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "        \n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset()\n",
    "dataloader = DataLoader(dataset,batch_size=2,shuffle=True)\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch_idx,samples in enumerate(dataloader):\n",
    "        x_train,y_train = samples\n",
    "        \n",
    "        prediction = model(x_train) # forward 계산\n",
    "        cost = nn.functional.mse_loss(prediction,y_train) # mse_loss 계산\n",
    "\n",
    "        optimizer.zero_grad() # gradient 초기화\n",
    "        cost.backward() #gradient 계산\n",
    "        optimizer.step() #optimizer 학습\n",
    "        \n",
    "        print(f'Epoch: {epoch} Batch: {batch_idx+1}/{len(dataloader) Cost: {cost.item()}} ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
